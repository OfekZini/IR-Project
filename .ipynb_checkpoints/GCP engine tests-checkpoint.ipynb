{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c85646e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # download nltk stopwords\n",
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a79ce3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install a particular version of `google-cloud-storage` because (oddly enough)\n",
    "# # the  version on Colab and GCP is old. A dependency error below is okay.\n",
    "# !pip install -q google-cloud-storage==1.43.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef61aa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init backend class\n"
     ]
    },
    {
     "ename": "NotFound",
     "evalue": "404 GET https://storage.googleapis.com/download/storage/v1/b/hw3ir322/o/text_stemmed%5Cindex.pkl?alt=media: No such object: hw3ir322/text_stemmed\\index.pkl: ('Request failed with status code', 404, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidResponse\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\google\\cloud\\storage\\client.py:1113\u001B[0m, in \u001B[0;36mClient.download_blob_to_file\u001B[1;34m(self, blob_or_uri, file_obj, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001B[0m\n\u001B[0;32m   1112\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1113\u001B[0m     \u001B[43mblob_or_uri\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1114\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtransport\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1115\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfile_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1116\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdownload_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1117\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1118\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstart\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1119\u001B[0m \u001B[43m        \u001B[49m\u001B[43mend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1120\u001B[0m \u001B[43m        \u001B[49m\u001B[43mraw_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1121\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1122\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchecksum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchecksum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1123\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1124\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1125\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m resumable_media\u001B[38;5;241m.\u001B[39mInvalidResponse \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\google\\cloud\\storage\\blob.py:1003\u001B[0m, in \u001B[0;36mBlob._do_download\u001B[1;34m(self, transport, file_obj, download_url, headers, start, end, raw_download, timeout, checksum, retry)\u001B[0m\n\u001B[0;32m   1002\u001B[0m download\u001B[38;5;241m.\u001B[39m_retry_strategy \u001B[38;5;241m=\u001B[39m retry_strategy\n\u001B[1;32m-> 1003\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mdownload\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconsume\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtransport\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1004\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_extract_headers_from_download(response)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\google\\resumable_media\\requests\\download.py:168\u001B[0m, in \u001B[0;36mDownload.consume\u001B[1;34m(self, transport, timeout)\u001B[0m\n\u001B[0;32m    166\u001B[0m result \u001B[38;5;241m=\u001B[39m _request_helpers\u001B[38;5;241m.\u001B[39mhttp_request(transport, method, url, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mrequest_kwargs)\n\u001B[1;32m--> 168\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    170\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\google\\resumable_media\\_download.py:185\u001B[0m, in \u001B[0;36mDownload._process_response\u001B[1;34m(self, response)\u001B[0m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_finished \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 185\u001B[0m \u001B[43m_helpers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequire_status_code\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    186\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_ACCEPTABLE_STATUS_CODES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_status_code\u001B[49m\n\u001B[0;32m    187\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\google\\resumable_media\\_helpers.py:99\u001B[0m, in \u001B[0;36mrequire_status_code\u001B[1;34m(response, status_codes, get_status_code, callback)\u001B[0m\n\u001B[0;32m     98\u001B[0m     callback()\n\u001B[1;32m---> 99\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m common\u001B[38;5;241m.\u001B[39mInvalidResponse(\n\u001B[0;32m    100\u001B[0m         response,\n\u001B[0;32m    101\u001B[0m         \u001B[38;5;124mu\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRequest failed with status code\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    102\u001B[0m         status_code,\n\u001B[0;32m    103\u001B[0m         \u001B[38;5;124mu\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected one of\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    104\u001B[0m         \u001B[38;5;241m*\u001B[39mstatus_codes\n\u001B[0;32m    105\u001B[0m     )\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m status_code\n",
      "\u001B[1;31mInvalidResponse\u001B[0m: ('Request failed with status code', 404, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mNotFound\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# you need to upload your implementation of search_app.py\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msearch_frontend\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mse\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Home Work\\Semester E\\Information Retrieval\\project\\jupyter test engine\\search_frontend.py:12\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m, host\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, port\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, debug\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions):\n\u001B[0;32m      7\u001B[0m         \u001B[38;5;28msuper\u001B[39m(MyFlaskApp, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mrun(host\u001B[38;5;241m=\u001B[39mhost, port\u001B[38;5;241m=\u001B[39mport, debug\u001B[38;5;241m=\u001B[39mdebug, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[1;32m---> 12\u001B[0m backend \u001B[38;5;241m=\u001B[39m \u001B[43mBackendClass\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m app \u001B[38;5;241m=\u001B[39m MyFlaskApp(\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m     14\u001B[0m app\u001B[38;5;241m.\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mJSONIFY_PRETTYPRINT_REGULAR\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Home Work\\Semester E\\Information Retrieval\\project\\jupyter test engine\\backend.py:68\u001B[0m, in \u001B[0;36mBackendClass.__init__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     64\u001B[0m title_doc_len_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtitle_stemmed/title_doc_lengths.pickle\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;66;03m# anchor_doc_len_path = 'anchor_stemmed/anchor_doc_lengths.pickle'\u001B[39;00m\n\u001B[0;32m     66\u001B[0m \n\u001B[0;32m     67\u001B[0m \u001B[38;5;66;03m# indices data members\u001B[39;00m\n\u001B[1;32m---> 68\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext_index \u001B[38;5;241m=\u001B[39m \u001B[43mInvertedIndex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_index\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext_idx_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbucket_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtitle_index \u001B[38;5;241m=\u001B[39m InvertedIndex\u001B[38;5;241m.\u001B[39mread_index(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtitle_idx_path, index_name, bucket_name)\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39manchor_index \u001B[38;5;241m=\u001B[39m InvertedIndex\u001B[38;5;241m.\u001B[39mread_index(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39manchor_idx_path, index_name, bucket_name)\n",
      "File \u001B[1;32m~\\Desktop\\Home Work\\Semester E\\Information Retrieval\\project\\jupyter test engine\\inverted_index_gcp.py:203\u001B[0m, in \u001B[0;36mInvertedIndex.read_index\u001B[1;34m(base_dir, name, bucket_name)\u001B[0m\n\u001B[0;32m    201\u001B[0m bucket \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m bucket_name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m get_bucket(bucket_name)\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _open(path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m, bucket) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m--> 203\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpickle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\google\\cloud\\storage\\fileio.py:138\u001B[0m, in \u001B[0;36mBlobReader.read\u001B[1;34m(self, size)\u001B[0m\n\u001B[0;32m    134\u001B[0m \u001B[38;5;66;03m# Download the blob. Checksumming must be disabled as we are using\u001B[39;00m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;66;03m# chunked downloads, and the server only knows the checksum of the\u001B[39;00m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;66;03m# entire file.\u001B[39;00m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 138\u001B[0m     result \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_blob\u001B[38;5;241m.\u001B[39mdownload_as_bytes(\n\u001B[0;32m    139\u001B[0m         start\u001B[38;5;241m=\u001B[39mfetch_start,\n\u001B[0;32m    140\u001B[0m         end\u001B[38;5;241m=\u001B[39mfetch_end,\n\u001B[0;32m    141\u001B[0m         checksum\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    142\u001B[0m         retry\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retry,\n\u001B[0;32m    143\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_download_kwargs\n\u001B[0;32m    144\u001B[0m     )\n\u001B[0;32m    145\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m RequestRangeNotSatisfiable:\n\u001B[0;32m    146\u001B[0m     \u001B[38;5;66;03m# We've reached the end of the file. Python file objects should\u001B[39;00m\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;66;03m# return an empty response in this case, not raise an error.\u001B[39;00m\n\u001B[0;32m    148\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\google\\cloud\\storage\\blob.py:1417\u001B[0m, in \u001B[0;36mBlob.download_as_bytes\u001B[1;34m(self, client, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001B[0m\n\u001B[0;32m   1415\u001B[0m client \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_require_client(client)\n\u001B[0;32m   1416\u001B[0m string_buffer \u001B[38;5;241m=\u001B[39m BytesIO()\n\u001B[1;32m-> 1417\u001B[0m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_blob_to_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1418\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1419\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstring_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1420\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstart\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1421\u001B[0m \u001B[43m    \u001B[49m\u001B[43mend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1422\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraw_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mraw_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1423\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_etag_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_etag_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1424\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_etag_not_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_etag_not_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1425\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_generation_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_generation_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1426\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_generation_not_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_generation_not_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1427\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_metageneration_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_metageneration_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1428\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_metageneration_not_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_metageneration_not_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1429\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1430\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchecksum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchecksum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1431\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1432\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1433\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m string_buffer\u001B[38;5;241m.\u001B[39mgetvalue()\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\google\\cloud\\storage\\client.py:1126\u001B[0m, in \u001B[0;36mClient.download_blob_to_file\u001B[1;34m(self, blob_or_uri, file_obj, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001B[0m\n\u001B[0;32m   1113\u001B[0m     blob_or_uri\u001B[38;5;241m.\u001B[39m_do_download(\n\u001B[0;32m   1114\u001B[0m         transport,\n\u001B[0;32m   1115\u001B[0m         file_obj,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1123\u001B[0m         retry\u001B[38;5;241m=\u001B[39mretry,\n\u001B[0;32m   1124\u001B[0m     )\n\u001B[0;32m   1125\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m resumable_media\u001B[38;5;241m.\u001B[39mInvalidResponse \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m-> 1126\u001B[0m     \u001B[43m_raise_from_invalid_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexc\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\google\\cloud\\storage\\blob.py:4466\u001B[0m, in \u001B[0;36m_raise_from_invalid_response\u001B[1;34m(error)\u001B[0m\n\u001B[0;32m   4460\u001B[0m     error_message \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(error)\n\u001B[0;32m   4462\u001B[0m message \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mu\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{method}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{url}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{error}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   4463\u001B[0m     method\u001B[38;5;241m=\u001B[39mresponse\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod, url\u001B[38;5;241m=\u001B[39mresponse\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39murl, error\u001B[38;5;241m=\u001B[39merror_message\n\u001B[0;32m   4464\u001B[0m )\n\u001B[1;32m-> 4466\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mfrom_http_status(response\u001B[38;5;241m.\u001B[39mstatus_code, message, response\u001B[38;5;241m=\u001B[39mresponse)\n",
      "\u001B[1;31mNotFound\u001B[0m: 404 GET https://storage.googleapis.com/download/storage/v1/b/hw3ir322/o/text_stemmed%5Cindex.pkl?alt=media: No such object: hw3ir322/text_stemmed\\index.pkl: ('Request failed with status code', 404, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>)"
     ]
    }
   ],
   "source": [
    "# # you need to upload your implementation of search_app.py\n",
    "# import search_frontend as se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f464991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('queries_train.json', 'rt') as f:\n",
    "  queries = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65238ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(true_list, predicted_list, k=40):\n",
    "    true_set = frozenset(true_list)\n",
    "    predicted_list = predicted_list[:k]\n",
    "    precisions = []\n",
    "    for i,doc_id in enumerate(predicted_list):\n",
    "        if doc_id in true_set:\n",
    "            prec = (len(precisions)+1) / (i+1)\n",
    "            precisions.append(prec)\n",
    "    if len(precisions) == 0:\n",
    "        return 0.0\n",
    "    return round(sum(precisions)/len(precisions),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d922f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(true_list, predicted_list, k):\n",
    "    true_set = frozenset(true_list)\n",
    "    predicted_list = predicted_list[:k]\n",
    "    if len(predicted_list) == 0:\n",
    "        return 0.0\n",
    "    return round(len([1 for doc_id in predicted_list if doc_id in true_set]) / len(predicted_list), 3)\n",
    "def recall_at_k(true_list, predicted_list, k):\n",
    "    true_set = frozenset(true_list)\n",
    "    predicted_list = predicted_list[:k]\n",
    "    if len(true_set) < 1:\n",
    "        return 1.0\n",
    "    return round(len([1 for doc_id in predicted_list if doc_id in true_set]) / len(true_set), 3)\n",
    "def f1_at_k(true_list, predicted_list, k):\n",
    "    p = precision_at_k(true_list, predicted_list, k)\n",
    "    r = recall_at_k(true_list, predicted_list, k)\n",
    "    if p == 0.0 or r == 0.0:\n",
    "        return 0.0\n",
    "    return round(2.0 / (1.0/p + 1.0/r), 3)\n",
    "def results_quality(true_list, predicted_list):\n",
    "    p5 = precision_at_k(true_list, predicted_list, 5)\n",
    "    f1_30 = f1_at_k(true_list, predicted_list, 30)\n",
    "    if p5 == 0.0 or f1_30 == 0.0:\n",
    "        return 0.0\n",
    "    return round(2.0 / (1.0/p5 + 1.0/f1_30), 3)\n",
    "\n",
    "assert precision_at_k(range(10), [1,2,3] , 2) == 1.0\n",
    "assert recall_at_k(   range(10), [10,5,3], 2) == 0.1\n",
    "assert precision_at_k(range(10), []      , 2) == 0.0\n",
    "assert precision_at_k([],        [1,2,3],  5) == 0.0\n",
    "assert recall_at_k(   [],        [10,5,3], 2) == 1.0\n",
    "assert recall_at_k(   range(10), [],       2) == 0.0\n",
    "assert f1_at_k(       [],        [1,2,3],  5) == 0.0\n",
    "assert f1_at_k(       range(10), [],       2) == 0.0\n",
    "assert f1_at_k(       range(10), [0,1,2],  2) == 0.333\n",
    "assert f1_at_k(       range(50), range(5), 30) == 0.182\n",
    "assert f1_at_k(       range(50), range(10), 30) == 0.333\n",
    "assert f1_at_k(       range(50), range(30), 30) == 0.75\n",
    "assert results_quality(range(50), range(5))  == 0.308\n",
    "assert results_quality(range(50), range(10)) == 0.5\n",
    "assert results_quality(range(50), range(30)) == 0.857\n",
    "assert results_quality(range(50), [-1]*5 + list(range(5,30))) == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ab2d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from time import time\n",
    "# In GCP the public URL for your engine should look like this:\n",
    "# url = 'http://35.232.59.3:8080'\n",
    "# In colab, we are going to send HTTP requests to localhost (127.0.0.1)\n",
    "# and direct them to port where the server is listening (5000).\n",
    "url = 'http://34.59.160.208:8080'\n",
    "\n",
    "# rq = None\n",
    "qs_res = []\n",
    "for q, true_wids in queries.items():\n",
    "  duration, ap = None, None\n",
    "  t_start = time()\n",
    "  try:\n",
    "    res = requests.get(url + '/search', {'query': q}, timeout=35)\n",
    "#     print(res.status_code)\n",
    "    duration = time() - t_start\n",
    "    if res.status_code == 200:\n",
    "      pred_wids, _ = zip(*res.json())\n",
    "      # print(pred_wids)\n",
    "      rq = results_quality(true_wids, pred_wids)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  qs_res.append((q, duration, rq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f34b5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Human Genome Project DNA mapping', 2.2067270278930664, 0.52), ('Italian pasta varieties and recipes', 1.9843201637268066, 0.113), ('Street food around the world', 5.177646636962891, 0.0), ('Surrealism art Salvador DalÃ­', 2.741309642791748, 0.357), ('Mediterranean diet health benefits', 2.027068853378296, 0.196), ('Civil Rights Movement 1960s protests', 4.126307010650635, 0.0), ('Manhattan Project atomic bomb', 1.9229867458343506, 0.259), ('Cheese types and production', 1.8407881259918213, 0.449), ('Anime history Japan Studio Ghibli', 3.385265588760376, 0.095), ('Berlin Wall fall reunification', 2.4191598892211914, 0.0), ('Sushi origins Japan', 1.8954296112060547, 0.139), ('World War I causes consequences', 6.011715650558472, 0.0), ('Higgs Boson discovery physics', 2.2113330364227295, 0.326), ('Golden Age of Hollywood films', 7.587707996368408, 0.046), ('Byzantine Empire Constantinople history', 1.4487926959991455, 0.448), ('Turing Machine early computing', 2.227163553237915, 0.245), ('Theory of Relativity Einstein', 1.4397296905517578, 0.366), ('Mobile phone technology evolution', 1.9249622821807861, 0.0), ('History of chocolate production', 1.4579274654388428, 0.0), ('Apollo 11 moon landing 1969', 2.385904312133789, 0.084), ('Gothic architecture medieval cathedrals', 1.6484570503234863, 0.462), ('Russian Revolution 1917 Bolsheviks', 1.9219412803649902, 0.366), ('Academy Awards history Oscars', 4.6062610149383545, 0.462), ('Fermentation food preservation techniques', 1.5368592739105225, 0.21), ('History of pizza Italian cuisine', 1.696504831314087, 0.436), ('French cuisine traditional dishes', 2.3298797607421875, 0.191), ('Endangered species conservation efforts', 2.4250001907348633, 0.323), ('Greek mythology Western culture', 2.649163246154785, 0.0), ('Cold War proxy conflicts', 3.422248363494873, 0.315), ('Nelson Mandela apartheid biography', 1.619638204574585, 0.179)]\n"
     ]
    }
   ],
   "source": [
    "print(qs_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a18a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "run_desc = \"bm25 k=1.2 B = 0.5\"\n",
    "# Add timestamp column\n",
    "timestamped_qs_res = [(q, duration, rq, datetime.now().strftime('%Y-%m-%d %H:%M:%S'),run_desc) for q, duration, rq in qs_res]\n",
    "\n",
    "# Convert results to a DataFrame (same as before)\n",
    "results_df = pd.DataFrame(timestamped_qs_res, columns=['Query', 'Duration', 'Results Quality', 'Timestamp','type'])\n",
    "\n",
    "# File path\n",
    "file_path = r'C:\\Users\\User\\Desktop\\Home Work\\Semester E\\Information Retrieval\\project\\jupyter test engine\\query_results.csv'\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    # Append to existing file\n",
    "    results_df.to_csv(file_path, mode='a', header=False, index=False)\n",
    "else:\n",
    "    # Create a new file with header\n",
    "    results_df.to_csv(file_path, mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ce2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
