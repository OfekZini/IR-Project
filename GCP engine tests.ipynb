{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c85646e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ofekzini/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download nltk stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f464991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('queries_train.json', 'rt') as f:\n",
    "  queries = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65238ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(true_list, predicted_list, k=40):\n",
    "    true_set = frozenset(true_list)\n",
    "    predicted_list = predicted_list[:k]\n",
    "    precisions = []\n",
    "    for i,doc_id in enumerate(predicted_list):\n",
    "        if doc_id in true_set:\n",
    "            prec = (len(precisions)+1) / (i+1)\n",
    "            precisions.append(prec)\n",
    "    if len(precisions) == 0:\n",
    "        return 0.0\n",
    "    return round(sum(precisions)/len(precisions),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d922f2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def precision_at_k(true_list, predicted_list, k):\n",
    "    true_set = frozenset(true_list)\n",
    "    predicted_list = predicted_list[:k]\n",
    "    if len(predicted_list) == 0:\n",
    "        return 0.0\n",
    "    return round(len([1 for doc_id in predicted_list if doc_id in true_set]) / len(predicted_list), 3)\n",
    "def recall_at_k(true_list, predicted_list, k):\n",
    "    true_set = frozenset(true_list)\n",
    "    predicted_list = predicted_list[:k]\n",
    "    if len(true_set) < 1:\n",
    "        return 1.0\n",
    "    return round(len([1 for doc_id in predicted_list if doc_id in true_set]) / len(true_set), 3)\n",
    "def f1_at_k(true_list, predicted_list, k):\n",
    "    p = precision_at_k(true_list, predicted_list, k)\n",
    "    r = recall_at_k(true_list, predicted_list, k)\n",
    "    if p == 0.0 or r == 0.0:\n",
    "        return 0.0\n",
    "    return round(2.0 / (1.0/p + 1.0/r), 3)\n",
    "def results_quality(true_list, predicted_list):\n",
    "    p5 = precision_at_k(true_list, predicted_list, 5)\n",
    "    print(p5)\n",
    "    f1_30 = f1_at_k(true_list, predicted_list, 30)\n",
    "    if p5 == 0.0 or f1_30 == 0.0:\n",
    "        return 0.0\n",
    "    return round(2.0 / (1.0/p5 + 1.0/f1_30), 3)\n",
    "\n",
    "assert precision_at_k(range(10), [1,2,3] , 2) == 1.0\n",
    "assert recall_at_k(   range(10), [10,5,3], 2) == 0.1\n",
    "assert precision_at_k(range(10), []      , 2) == 0.0\n",
    "assert precision_at_k([],        [1,2,3],  5) == 0.0\n",
    "assert recall_at_k(   [],        [10,5,3], 2) == 1.0\n",
    "assert recall_at_k(   range(10), [],       2) == 0.0\n",
    "assert f1_at_k(       [],        [1,2,3],  5) == 0.0\n",
    "assert f1_at_k(       range(10), [],       2) == 0.0\n",
    "assert f1_at_k(       range(10), [0,1,2],  2) == 0.333\n",
    "assert f1_at_k(       range(50), range(5), 30) == 0.182\n",
    "assert f1_at_k(       range(50), range(10), 30) == 0.333\n",
    "assert f1_at_k(       range(50), range(30), 30) == 0.75\n",
    "assert results_quality(range(50), range(5))  == 0.308\n",
    "assert results_quality(range(50), range(10)) == 0.5\n",
    "assert results_quality(range(50), range(30)) == 0.857\n",
    "assert results_quality(range(50), [-1]*5 + list(range(5,30))) == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab2d381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Genome Project DNA mapping\n",
      "0.8\n",
      "Italian pasta varieties and recipes\n",
      "0.2\n",
      "Street food around the world\n",
      "0.4\n",
      "Surrealism art Salvador DalÃ­\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from time import time\n",
    "# In GCP the public URL for your engine should look like this:\n",
    "# url = 'http://35.232.59.3:8080'\n",
    "# In colab, we are going to send HTTP requests to localhost (127.0.0.1)\n",
    "# and direct them to port where the server is listening (5000).\n",
    "url = 'http://34.59.160.208:8080'\n",
    "\n",
    "# rq = None\n",
    "qs_res = []\n",
    "for q, true_wids in queries.items():\n",
    "  duration, ap = None, None\n",
    "  t_start = time()\n",
    "  try:\n",
    "    res = requests.get(url + '/search', {'query': q}, timeout=35)\n",
    "#     print(res.status_code)\n",
    "    duration = time() - t_start\n",
    "    print(q)\n",
    "    if res.status_code == 200:\n",
    "      pred_wids, _ = zip(*res.json())\n",
    "      # print(pred_wids)\n",
    "      rq = results_quality(true_wids, pred_wids)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  qs_res.append((q, duration, rq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f34b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qs_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3a18a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "text_weight = 1.5\n",
    "title_weight = 0.6\n",
    "anchor_weight = 0.1\n",
    "pr_weight = 0.4\n",
    "pv_weight = 0.5\n",
    "\n",
    "run_desc = f\"CSanchor BMtitle, text_weight, c200 = {text_weight}, title_weight ={title_weight}, anchor_weight = {anchor_weight},pr_weight = {pr_weight},pv_weight = {pv_weight}\"\n",
    "# Add timestamp column\n",
    "timestamped_qs_res = [(q, duration, rq, datetime.now().strftime('%Y-%m-%d %H:%M:%S'),run_desc) for q, duration, rq in qs_res]\n",
    "\n",
    "# Convert results to a DataFrame (same as before)\n",
    "results_df = pd.DataFrame(timestamped_qs_res, columns=['Query', 'Duration', 'Results Quality', 'Timestamp','type'])\n",
    "\n",
    "# File path\n",
    "file_path = r'query_results.csv'\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    # Append to existing file\n",
    "    results_df.to_csv(file_path, mode='a', header=False, index=False)\n",
    "else:\n",
    "    # Create a new file with header\n",
    "    results_df.to_csv(file_path, mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ce2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
